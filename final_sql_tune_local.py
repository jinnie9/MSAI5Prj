import os
from dotenv import load_dotenv
import streamlit as st
import pandas as pd
from datetime import datetime, timedelta
import threading, glob, json, requests
from azure.storage.blob import BlobServiceClient
from openai import AzureOpenAI
from st_aggrid import AgGrid, GridOptionsBuilder, GridUpdateMode

# -----------------------
# ì„¤ì •
# -----------------------
load_dotenv()
BLOB_CONN_STR = os.getenv("BLOB_CONN_STR")
CONTAINER = "msaiquery"

OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
OPENAI_API_VERSION = os.getenv("OPENAI_API_VERSION")
AZURE_ENDPOINT = os.getenv("AZURE_ENDPOINT")

AUTO_FETCH_INTERVAL = 300
CACHE_TTL = 600

# -----------------------
# Blob Storage ì´ˆê¸°í™”
# -----------------------
@st.cache_resource
def get_blob_container():
    try:
        blob_service = BlobServiceClient.from_connection_string(BLOB_CONN_STR)
        return blob_service.get_container_client(CONTAINER)
    except:
        return None

container_client = get_blob_container()

# -----------------------
# OpenAI ì´ˆê¸°í™”
# -----------------------
@st.cache_resource
def get_openai_client():
    try:
        client = AzureOpenAI(
            api_key=OPENAI_API_KEY,
            api_version=OPENAI_API_VERSION,
            azure_endpoint=AZURE_ENDPOINT
        )
        return client
    except:
        return None

client = get_openai_client()

# -----------------------
# SQL íŠœë‹
# -----------------------
def tune_sql_with_openai(sql_text: str):
    if not client:
        return "OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” í•„ìš”"
    if not sql_text or sql_text.strip() == "" or sql_text == "SQL ì •ë³´ ì—†ìŒ":
        return "íŠœë‹í•  SQL ì—†ìŒ"
    prompt = f"SQL ìµœì í™”: {sql_text}"
    try:
        resp = client.chat.completions.create(
            model="gpt-4.1-mini",
            messages=[{"role": "user", "content": prompt}],
            max_tokens=1000
        )
        return resp.choices[0].message.content
    except Exception as e:
        return f"íŠœë‹ ì˜¤ë¥˜: {e}"

# -----------------------
# ë¡œì»¬ JSON ë¡œë“œ
# -----------------------
@st.cache_data(ttl=CACHE_TTL)
def load_data_local(folder="data"):
    records = []
    for file in glob.glob(f"{folder}/*.json"):
        try:
            with open(file,'r',encoding='utf-8') as f:
                data = json.load(f)
            if isinstance(data, dict):
                data = [data]
            for r in data:
                r.setdefault("timestamp", datetime.now().isoformat())
                r.setdefault("app_name", "unknown")
                r.setdefault("elapse_time", 0.0)
                r.setdefault("user_ip", "0.0.0.0")
                r.setdefault("cfg_path", "/config/default")
                r.setdefault("sql", None)
                records.append(r)
        except:
            continue
    if records:
        df = pd.DataFrame(records)
        df["timestamp"] = pd.to_datetime(df["timestamp"], errors='coerce').fillna(datetime.now())
        df["elapse_time"] = pd.to_numeric(df["elapse_time"], errors='coerce').fillna(0.0)
        df["sql"] = df["sql"].fillna("SQL ì •ë³´ ì—†ìŒ")
        return df
    else:
        return pd.DataFrame(columns=["timestamp","app_name","elapse_time","user_ip","cfg_path","sql"])

# -----------------------
# Blob ë°ì´í„° ë¡œë“œ
# -----------------------
@st.cache_data(ttl=CACHE_TTL)
def load_data_blob(start, end):
    if not container_client:
        return pd.DataFrame(columns=["timestamp","app_name","elapse_time","user_ip","cfg_path","sql"])
    records = []
    for blob in container_client.list_blobs():
        try:
            data_bytes = container_client.download_blob(blob.name).readall()
            data = json.loads(data_bytes)
            if isinstance(data, dict):
                data = [data]
            for r in data:
                r.setdefault("timestamp", datetime.now().isoformat())
                r.setdefault("app_name", "unknown")
                r.setdefault("elapse_time", 0.0)
                r.setdefault("user_ip", "0.0.0.0")
                r.setdefault("cfg_path", "/config/default")
                r.setdefault("sql", None)
                records.append(r)
        except:
            continue
    if records:
        df = pd.DataFrame(records)
        df["timestamp"] = pd.to_datetime(df["timestamp"], errors='coerce')
        df = df[(df["timestamp"] >= start) & (df["timestamp"] <= end)]
        df["elapse_time"] = pd.to_numeric(df["elapse_time"], errors='coerce').fillna(0.0)
        df["sql"] = df["sql"].fillna("SQL ì •ë³´ ì—†ìŒ")
        return df
    return pd.DataFrame(columns=["timestamp","app_name","elapse_time","user_ip","cfg_path","sql"])

# -----------------------
# URL í˜¸ì¶œ -> Blob ì €ì¥
# -----------------------
def fetch_json_to_blob(url):
    if not container_client:
        st.error("Blob Storage í•„ìš”")
        return
    try:
        resp = requests.get(url, timeout=30)
        resp.raise_for_status()
        data = resp.json()
        now = datetime.utcnow()
        blob_name = f"logs/{now.strftime('%Y/%m/%d/%H/%M')}.json"
        container_client.upload_blob(blob_name, json.dumps(data), overwrite=True)
    except Exception as e:
        st.error(f"URL fetch ì˜¤ë¥˜: {e}")

def run_periodic_fetch(url, interval_sec=AUTO_FETCH_INTERVAL):
    while True:
        fetch_json_to_blob(url)
        threading.Event().wait(interval_sec)

# -----------------------
# Streamlit UI
# -----------------------
st.title("Elapse Time ëª¨ë‹ˆí„°ë§ & SQL íŠœë‹")

# ìë™ ìƒˆë¡œê³ ì¹¨
refresh_interval = st.number_input("í˜ì´ì§€ ìë™ ìƒˆë¡œê³ ì¹¨(ì´ˆ)", min_value=30, max_value=3600, value=600)
st.components.v1.html(f"<meta http-equiv='refresh' content='{refresh_interval}'>", height=0)

# ë°ì´í„° ì†ŒìŠ¤ ì„ íƒ
mode = st.radio("ë°ì´í„° ì†ŒìŠ¤", ["ë¡œì»¬ JSON", "Blob Storage"])

# ìš´ì˜ URL ìˆ˜ì§‘
if mode=="Blob Storage":
    url_input = st.text_input("API URL")
    if st.button("ì£¼ê¸°ì  ìˆ˜ì§‘ ì‹œì‘") and url_input:
        thread = threading.Thread(target=run_periodic_fetch, args=(url_input,), daemon=True)
        thread.start()
        st.success(f"ì£¼ê¸°ì  ìˆ˜ì§‘ ì‹œì‘ ({AUTO_FETCH_INTERVAL}ì´ˆ ê°„ê²©)")

# ë‚ ì§œ ë²”ìœ„
col1, col2 = st.columns(2)
start_date = col1.date_input("ì‹œì‘ì¼", datetime.now()-timedelta(days=1))
end_date = col2.date_input("ì¢…ë£Œì¼", datetime.now())
start_dt = datetime.combine(start_date, datetime.min.time())
end_dt = datetime.combine(end_date, datetime.max.time())

# ë°ì´í„° ë¡œë“œ
df = load_data_local() if mode=="ë¡œì»¬ JSON" else load_data_blob(start_dt,end_dt)
df = df[(df["timestamp"] >= start_dt) & (df["timestamp"] <= end_dt)]
st.info(f"ì´ {len(df)}ê°œ ë ˆì½”ë“œ ë¡œë“œ")

if df.empty:
    st.warning("í‘œì‹œí•  ë°ì´í„° ì—†ìŒ")
    st.stop()

# cfg_path í•„í„°
cfg_options = df["cfg_path"].dropna().unique().tolist()
cfg_filter = st.multiselect("cfg_path í•„í„°", cfg_options)
if cfg_filter:
    df = df[df["cfg_path"].isin(cfg_filter)]

# ì‹œê°„ëŒ€/ cfg_path í‰ê·  ê·¸ë˜í”„
avg_df = df.groupby([pd.Grouper(key="timestamp", freq="10min"), "cfg_path"])["elapse_time"].mean().reset_index()
if not avg_df.empty:
    st.subheader("ì‹œê°„ëŒ€ / cfg_pathë³„ í‰ê·  Elapse Time")
    st.line_chart(avg_df, x="timestamp", y="elapse_time", color="cfg_path")

# Top10
top10_display = df.nlargest(10, "elapse_time").copy()
top10_display["sql"] = top10_display["sql"].fillna("SQL ì •ë³´ ì—†ìŒ")

st.subheader("Top10 Elapse Time")
gb = GridOptionsBuilder.from_dataframe(top10_display)
gb.configure_selection("single", use_checkbox=False)
gb.configure_column("sql", wrapText=True, autoHeight=True, width=400)
grid_options = gb.build()
grid_response = AgGrid(top10_display, gridOptions=grid_options, update_mode=GridUpdateMode.SELECTION_CHANGED, height=300)

# session_state ì´ˆê¸°í™”
if "selected_sql" not in st.session_state:
    st.session_state.selected_sql = None

# ì„ íƒ í–‰ ì²˜ë¦¬
selected_rows = grid_response.get("selected_rows", [])
if selected_rows is not None and selected_rows.shape[0] > 0:
    # print(selected_rows.head())
    # row_data = selected_rows[0]
    target_row = selected_rows.iloc[0]
    st.session_state.selected_sql = target_row.get("sql", "SQL ì •ë³´ ì—†ìŒ")
    # st.session_state.selected_sql = row_data.get("sql", "SQL ì •ë³´ ì—†ìŒ")

# SQL í‘œì‹œ + íŠœë‹ ë²„íŠ¼
st.subheader("ì„ íƒí•œ SQL")
st.code(st.session_state.selected_sql or "SQL ì •ë³´ ì—†ìŒ", language="sql")
if st.button("ğŸš€ AIë¡œ SQL íŠœë‹í•˜ê¸°"):
    with st.spinner("ì‘ë‹µì„ ê¸°ë‹¤ë¦¬ëŠ” ì¤‘..."):
        if st.session_state.selected_sql and st.session_state.selected_sql != "SQL ì •ë³´ ì—†ìŒ":
            advice = tune_sql_with_openai(st.session_state.selected_sql)
            st.markdown("### ğŸ” AI SQL íŠœë‹ ê²°ê³¼")
            st.code(advice, language="sql")
        else:
            st.warning("íŠœë‹í•  SQL ì—†ìŒ")
